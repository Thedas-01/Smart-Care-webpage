<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Smart-Care</title>
    <link href="css/literature_servey.css" rel="stylesheet" />
  </head>
  <body>
    <div class="container">
      <h1>Literature Survey</h1>
      <ul class="custom-list">
        <li>
          Healthcare technologies have witnessed substantial advances with the introduction of AI, IoT, and mobile health 
          solutions targeting specific challenges like fall detection, wound classification, resource management, and blood 
          bank coordination. Fall detection systems, as surveyed by Prabath et al. (2021) and Patil et al. (2020), have primarily 
          relied on wearable sensors and single-modal detection algorithms. While these systems demonstrate promise in controlled 
          environments, their practical deployment often suffers from limited accuracy, high false-positive rates, and dependence on 
          manual activation, restricting autonomous emergency response capabilities. Integrating multi-sensor fusion and automated 
          alerting mechanisms with GPS-based location tracking remains a crucial area requiring further innovation (Jayadeep, 2020; Ali et al., 2021).
        </li>

        <li>
          In parallel, AI-driven wound classification has seen significant research progress. 
          Deep learning models, particularly convolutional neural networks (CNNs), have achieved high classification 
          accuracy in curated clinical datasets (Zhang & Zhang, 2018; Yang & Li, 2019). However, practical challenges 
          arise due to the variability in image capture conditions typical in emergency or mobile healthcare settings, 
          such as inconsistent lighting and angles (Patel & Saini, 2020). Furthermore, many existing studies emphasize 
          classification performance but lack integration with clinical workflows or decision support for triage and treatment, 
          limiting their utility in fast-paced emergency environments.
        </li>

        <li>
          In parallel, AI-driven wound classification has seen significant research progress. Deep learning models, particularly 
          convolutional neural networks (CNNs), have achieved high classification accuracy in curated clinical datasets (Zhang & Zhang, 2018; 
          Yang & Li, 2019). However, practical challenges arise due to the variability in image capture conditions typical in emergency or mobile 
          healthcare settings, such as inconsistent lighting and angles (Patel & Saini, 2020). Furthermore, many existing studies emphasize 
          classification performance but lack integration with clinical workflows or decision support for triage and treatment, limiting their 
          utility in fast-paced emergency environments.

        </li>
      </ul>
    </div>
  </body>
</html>
